{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data_loader, move_data_to_device, MyDataset\n",
    "from hparams import Hparams\n",
    "\n",
    "\n",
    "args = Hparams.args\n",
    "dataset = MyDataset(\n",
    "        dataset_root=args['dataset_root'],\n",
    "        split='train',\n",
    "        sampling_rate=args['sampling_rate'],\n",
    "        sample_length=args['sample_length'],\n",
    "        frame_size=args['frame_size'],\n",
    "        song_fns=None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def testItem(idx=0):\n",
    "    print(f\"samplerate: {dataset.sampling_rate }\")\n",
    "    pYinFrameTime = librosa.frames_to_time(dataset.sample_length, sr=dataset.sampling_rate, hop_length=200)\n",
    "    melspecFrameTime = librosa.frames_to_time(dataset.sample_length, sr=dataset.sampling_rate, hop_length=321)\n",
    "    print(f\"melspec FrameTime: {melspecFrameTime}\")\n",
    "    print(f\"pYin FrameTime: {pYinFrameTime}\")\n",
    "    \n",
    "    mel_spectrogram, yin, pyin = dataset.__getitem__(idx)\n",
    "    print(mel_spectrogram.shape[1])\n",
    "    print(yin.shape)\n",
    "    print(pyin.shape)\n",
    "\n",
    "testItem(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import pinyin\n",
    "\n",
    "\n",
    "def read_aidatatang_index(data_root=os.path.join(os.getcwd(),\"data_full\")):\n",
    "\n",
    "    # handling transcripts\n",
    "    transcript_path = os.path.join(data_root, 'aidatatang', 'transcript', 'aidatatang_200_zh_transcript.txt')\n",
    "    with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    def parseLine(line):\n",
    "        split = line.split(' ')\n",
    "        transcriptIDX = split[0]\n",
    "        # T0055 G0002 S0002\n",
    "        prefix = transcriptIDX[:5]\n",
    "        participant_id = transcriptIDX[5:10]\n",
    "        sentence_id = transcriptIDX[10:]\n",
    "        \n",
    "        text = split[1:]\n",
    "        text,text_ids = extract_pinyin(list(' '.join(text).strip()))\n",
    "        return participant_id,sentence_id, text,text_ids\n",
    "    \n",
    "    lines=[parseLine(line) for line in lines]\n",
    "\n",
    "    # handling actual index\n",
    "    def read_subfolder(subfolder_path):\n",
    "        files = os.listdir(subfolder_path)\n",
    "        return files\n",
    "    \n",
    "    subfolders = [\"dev\",\"test\",\"train\"]\n",
    "    subfolder_index= {subfolder:sorted(read_subfolder(os.path.join(data_root, 'aidatatang', 'corpus', subfolder))) for subfolder in subfolders}\n",
    "    for subfolder in subfolders:\n",
    "        indexing = set(subfolder_index[subfolder])\n",
    "        # sanity\n",
    "        assert len(indexing) == len(subfolder_index[subfolder])\n",
    "        subfolder_index[subfolder] = indexing \n",
    "\n",
    "    df = pd.DataFrame.from_records(data = lines, columns=[\"participantID\", \"sentenceID\", \"transcript\", \"toneclass\"])\n",
    "    \n",
    "    def get_category(x):\n",
    "        pid = x[\"participantID\"]\n",
    "        fname = f\"{pid}.tar.gz\"\n",
    "        for subfolder in subfolders:\n",
    "            if fname in subfolder_index[subfolder]:\n",
    "                return subfolder\n",
    "        raise ValueError(f\"Could not find {fname} in any subfolder\")\n",
    "\n",
    "    df[\"folder\"] = df.apply(get_category, axis=1)\n",
    "    return df\n",
    "\n",
    "def extract_pinyin(sentence_word_list):\n",
    "    pinyin_word_list = [pinyin.get(x, format=\"numerical\", delimiter=\" \") for x in sentence_word_list]\n",
    "    pinyin_word_list_tone_class = [int(x[-1]) if len(x)>1 else 0 for x in pinyin_word_list]\n",
    "    return pinyin_word_list,pinyin_word_list_tone_class\n",
    "    \n",
    "def read_aidatatang_data(participantID, sentenceID):\n",
    "\n",
    "    fullFileName = f\"T0055{participantID}{sentenceID}\"\n",
    "    data_root=os.path.join(os.getcwd(),\"data_full\")\n",
    "    makePath = lambda x,y: os.path.join(data_root, 'aidatatang_200zh', 'corpus', x, f\"{y}.tar.gz\")\n",
    "    subfolders = [\"dev\",\"test\",\"train\"]\n",
    "    possiblePaths = [makePath(subfolder,participantID) for subfolder in subfolders]\n",
    "    zipped_path = [path for path in possiblePaths if os.path.exists(path)][0]\n",
    "\n",
    "\n",
    "    suffixed = {\n",
    "        'AudioData': (\".wav\",lambda x: librosa.load(x)[0]) ,\n",
    "        \"MetaData\": (\".txt\", lambda x: extract_pinyin(x.read().decode(\"utf-8\"))), \n",
    "        \"Transcript\": (\".trn\", lambda x: x.read().decode(\"utf-8\"))\n",
    "        }\n",
    "\n",
    "    with tarfile.open(zipped_path, 'r',) as tar_ref:\n",
    "        print(tar_ref.getnames())\n",
    "        data =  {\n",
    "            suf[0]: suf[1][1](tar_ref.extractfile(f\"./{participantID}/{fullFileName}{suf[1][0]}\")) for suf in suffixed.items()\n",
    "        }\n",
    "    for x in data:\n",
    "        print(x, data[x])\n",
    "\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "read_aidatatang_index()\n",
    "\n",
    "# d = read_aidatatang_data(*read_aidatatang_index()[0][3][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(d['AudioData'], sr=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "\n",
    "def spectralFlux():\n",
    "    audioData = d['AudioData']\n",
    "    # sosfilt = signal.butter(2,(20,200), 'bp', fs=16000, output='sos')\n",
    "    # audioData = signal.sosfilt(sosfilt, audioData)\n",
    "    # audioData = audioData[np.abs(audioData)<np.mean(np.abs(audioData))]\n",
    "\n",
    "    melspec = librosa.feature.melspectrogram(y= audioData, sr=16000, n_fft=2048, hop_length=128, n_mels=256)\n",
    "\n",
    "\n",
    "    onsets = librosa.onset.onset_detect(y =audioData, sr=16000, hop_length=200,)\n",
    "    timings = librosa.frames_to_time(onsets, sr=16000, hop_length=200)\n",
    "\n",
    "    fundamental ,voiced, probability = librosa.pyin(audioData, sr=16000, hop_length=200, fmin=20, fmax = 8000)\n",
    "    fundamental_max = np.nanmax(fundamental)\n",
    "    fundamental_min = np.nanmin(fundamental)\n",
    "    fundamental_range = fundamental_max - fundamental_min\n",
    "\n",
    "    fundamental = np.nan_to_num(fundamental,nan=np.nanmean(fundamental))\n",
    "    fundamental = (fundamental - fundamental_min) / fundamental_range\n",
    "\n",
    "    gradients = np.gradient(fundamental)\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=6, figsize=(15, 20))\n",
    "    ax,ax2, ax3, ax4,ax5,ax6 =axs\n",
    "    librosa.display.waveshow(audioData, sr=16000, ax=ax)\n",
    "    librosa.display.waveshow(fundamental, sr=int(16000/200), ax=ax2)\n",
    "    librosa.display.waveshow(gradients, sr=int(16000/200), ax=ax3)\n",
    "\n",
    "    librosa.display.waveshow(voiced.astype(np.float32), sr=int(16000/200), ax=ax4)\n",
    "    librosa.display.waveshow(probability.astype(np.float32), sr=int(16000/200), ax=ax5)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(melspec), sr=16000, hop_length=128, ax=ax6)\n",
    "\n",
    "\n",
    "    ax2.set_ylim(0,1)\n",
    "    # print(fundamental)\n",
    "\n",
    "\n",
    "    ax.vlines(timings, -1, 1, color='r', alpha=0.9, linestyle='--', label='Onsets')\n",
    "spectralFlux()\n",
    "# wo3 lao3 po2 shi4 da4 ben4 dan4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_michigan_dataset_index(data_root=os.path.join(os.getcwd(),\"data_full\")):\n",
    "\n",
    "    # handling transcripts\n",
    "    audio = os.path.join(data_root, 'michigan', 'tone_perfect_all_mp3', 'tone_perfect')\n",
    "    transcripts= os.path.join(data_root, 'michigan', 'tone_perfect_all_xml', 'tone_perfect')\n",
    "    \n",
    "    audioIndex = os.listdir(audio)\n",
    "    transcriptIndex = os.listdir(transcripts)\n",
    "    # ignoreing the metadata for now\n",
    "    \n",
    "    def parseAudioIndex(filename):\n",
    "        elem = filename.split(\"_\")\n",
    "        word = elem[0]\n",
    "        word_tone_class = int(word[-1]) \n",
    "        particpantID = elem[1]\n",
    "        return (particpantID, word, word_tone_class, filename)\n",
    "    \n",
    "    audioData = [parseAudioIndex(filename) for filename in audioIndex]\n",
    "    return pd.DataFrame.from_records(data=audioData, columns=[\"participantID\", \"word\", \"toneclass\", \"filename\"])\n",
    "\n",
    "\n",
    "def read_michigan_dataset_audio(filename, \n",
    "                                data_root=os.path.join(os.getcwd(),\"data_full\"),\n",
    "                                sr = 16000,\n",
    "                                mono=True\n",
    "                                ):\n",
    "    filepath = os.path.join(data_root, 'michigan', 'tone_perfect_all_mp3', 'tone_perfect', filename)\n",
    "    return librosa.load(filepath, sr=sr, mono=mono)[0]\n",
    "\n",
    "\n",
    "read_michigan_dataset_audio(read_michigan_dataset_index().iloc[0][\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import sklearn.model_selection\n",
    "from hparams import Hparams_michigan\n",
    "from dataset import read_michigan_dataset_index\n",
    "\n",
    "def get_data_loader_michigan(args):\n",
    "        # dataset_root=args['dataset_root'],\n",
    "        # split=split,\n",
    "        # sampling_rate=args['sampling_rate'],\n",
    "        # sample_length=args['sample_length'],\n",
    "        # frame_size=args['frame_size'],\n",
    "    index = read_michigan_dataset_index()\n",
    "    tone_classes = index[\"toneclass\"].values\n",
    "    ids = list(range(len(index)))\n",
    "    train_ids, test_ids= sklearn.model_selection.train_test_split(ids, test_size=0.2, random_state=42, shuffle=True, stratify=tone_classes)\n",
    "\n",
    "    train_index = index.iloc[train_ids]\n",
    "    test_index = index.iloc[test_ids]\n",
    "\n",
    "    train_ds = dataset.DatasetMichigan(\n",
    "        dataset_index=train_index, \n",
    "        dataset_root=args['dataset_root'], \n",
    "        sampling_rate=args['sampling_rate'], \n",
    "        preload_audio=args['preload_audio'],\n",
    "        sample_length=args['sample_length'],\n",
    "        pad_audio=args['pad_audio'],\n",
    "        )\n",
    "    \n",
    "    test_ds = dataset.DatasetMichigan(\n",
    "        dataset_index=test_index, \n",
    "        dataset_root=args['dataset_root'], \n",
    "        sampling_rate=args['sampling_rate'], \n",
    "        preload_audio=args['preload_audio'],\n",
    "        sample_length=args['sample_length'],\n",
    "        pad_audio=args['pad_audio'],\n",
    "        )\n",
    "    return train_ds, test_ds\n",
    "get_data_loader_michigan(Hparams_michigan.args)[0].plot_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_loader_michigan(Hparams_michigan.args)[1].plot_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot_item(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
