{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27470f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from hparams import *\n",
    "from dataset import  get_data_loader, get_data_loader_michigan\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new jupyter notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = get_data_loader(split='train', args=Hparams.args)\n",
    "for data in tqdm(train_loader):\n",
    "    mel_spectrogram, yin, pyin = data#move_data_to_device(data, 'cpu')\n",
    "    print(mel_spectrogram.shape)\n",
    "    print(yin.shape)\n",
    "    print(pyin.shape)\n",
    "    #assert list(x.shape) == [8, 250, 256]  # shape in [B, T, D],\n",
    "                                # i.e., [Batch size, num of frame per sample, spectrogram feature dimension]\n",
    "    #assert list(onset.shape) == list(offset.shape) == list(octave.shape) == list(pitch_class.shape) == [8, 250]\n",
    "    break\n",
    "print('Congrats!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b11fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the Michigan dataset\n",
    "train_ds, test_ds, data_loader_train, data_loader_test = get_data_loader_michigan(args=Hparams_michigan.args, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d28c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# to plot\n",
    "# train_ds.plot_item(0)\n",
    "\n",
    "# data loading\n",
    "for data in tqdm(data_loader_train):\n",
    "    mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, toneclass = data\n",
    "    print(f\"(Batch, feature)\")\n",
    "    print(f\"Spectrogram: {mel_spectrogram_normalised_log_scale_torch.shape} {type(mel_spectrogram_normalised_log_scale_torch)}\")\n",
    "    print(f\"Yin: {yin_normalised_torch.shape} {type(yin_normalised_torch)}\")\n",
    "    print(f\"Pyin: {pyin_normalised_torch.shape} {type(pyin_normalised_torch)}\")\n",
    "    print(f\"Word: {len(word)} {type(word)}\")\n",
    "    print(f\"Toneclass: {toneclass.shape} {type(toneclass)} {toneclass}\")\n",
    "    break\n",
    "print('Congrats!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.buffer = {}\n",
    "\n",
    "    def update(self, out, tgt, loss):\n",
    "        with torch.no_grad():\n",
    "            out = out.argmax(dim=1)\n",
    "            out = torch.flatten(out)\n",
    "            tgt = torch.flatten(tgt)\n",
    "\n",
    "            acc = accuracy_score(tgt.cpu(), out.cpu())\n",
    "\n",
    "            batch_metric = {\n",
    "                'loss': loss.item(),\n",
    "                'accuracy': acc,\n",
    "            }\n",
    "\n",
    "            for k in batch_metric:\n",
    "                if k in self.buffer:\n",
    "                    self.buffer[k].append(batch_metric[k])\n",
    "                else:\n",
    "                    self.buffer[k] = [batch_metric[k]]\n",
    "\n",
    "    def get_value(self):\n",
    "        for k in self.buffer:\n",
    "            self.buffer[k] = sum(self.buffer[k]) / len(self.buffer[k])\n",
    "        ret = self.buffer\n",
    "        self.buffer = {}\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data_loader, move_data_to_device\n",
    "\n",
    "\n",
    "def fit(model, args, learning_params):\n",
    "    # Set paths\n",
    "    save_model_dir = f\"{args['save_model_dir']}{model.feat_dim}_lr-{learning_params['lr']}\"\n",
    "    if not os.path.exists(save_model_dir):\n",
    "        os.mkdir(save_model_dir)\n",
    "\n",
    "    model.to(args['device'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_params['lr'])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    metric = Metrics()\n",
    "\n",
    "    # Start training\n",
    "    print('Start training...')\n",
    "    start_time = time.time()\n",
    "    best_model_id = -1\n",
    "    min_valid_loss = 10000\n",
    "    prev_loss = 10000\n",
    "    threshold = 1e-6\n",
    "\n",
    "    for epoch in range(1, learning_params['epoch'] + 1):\n",
    "        model.train()\n",
    "        \n",
    "        # Train\n",
    "        pbar = tqdm(data_loader_train)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "            tone_class -= 1 # 0-index\n",
    "        \n",
    "            x = mel_spectrogram_normalised_log_scale_torch.to(args['device'])\n",
    "            x = x[:, None, :, :]\n",
    "            tgt = tone_class.to(args['device'])\n",
    "            out = model(x)\n",
    "            loss = loss_func(out, tgt)\n",
    "            metric.update(out, tgt, loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description('Epoch {}, Loss: {:.4f}'.format(epoch, loss.item()))\n",
    "        metric_train = metric.get_value()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(data_loader_test):\n",
    "                mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "                tone_class -= 1 # 0-index\n",
    "\n",
    "                x = mel_spectrogram_normalised_log_scale_torch.to(args['device'])\n",
    "                x = x[:, None, :, :]\n",
    "                tgt = tone_class.to(args['device'])\n",
    "                out = model(x)\n",
    "                loss = loss_func(out, tgt)\n",
    "                metric.update(out, tgt, loss)\n",
    "        metric_test = metric.get_value()\n",
    "\n",
    "        # Logging\n",
    "        print('[Epoch {:02d}], Train Loss: {:.5f}, Valid Loss {:.5f}, Time {:.2f}s'.format(\n",
    "            epoch, metric_train['loss'], metric_test['loss'], time.time() - start_time,\n",
    "        ))\n",
    "        print('Split Train Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_train['loss'],\n",
    "            metric_train['accuracy']\n",
    "        ))\n",
    "        print('Split Test Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_test['loss'],\n",
    "            metric_test['accuracy']\n",
    "        ))\n",
    "\n",
    "        # Save the best model\n",
    "        if metric_test['loss'] < min_valid_loss:\n",
    "            min_valid_loss = metric_test['loss']\n",
    "            best_model_id = epoch\n",
    "\n",
    "            save_dict = model.state_dict()\n",
    "            target_model_path = save_model_dir + '/best_model.pth'\n",
    "            torch.save(save_dict, target_model_path)\n",
    "\n",
    "        if abs(metric_test['loss'] - prev_loss) < threshold:\n",
    "            break\n",
    "\n",
    "        prev_loss = metric_test['loss']\n",
    "\n",
    "    print('Training done in {:.1f} minutes.'.format((time.time() - start_time) / 60))\n",
    "    return best_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fe830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning params\n",
    "learning_params = {\n",
    "    'epoch': 10,\n",
    "    'lr': 1e-3,\n",
    "}\n",
    "\n",
    "model = ToneEval_Base(input_shape=(1, 128, 75))\n",
    "fit(model, args=Hparams.args, learning_params=learning_params)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
