{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa9f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 5])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "Congrats!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#new jupyter notebook\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data_loader, move_data_to_device\n",
    "from hparams import Hparams\n",
    "\n",
    "train_loader = get_data_loader(split='train', args=Hparams.args)\n",
    "for data in tqdm(train_loader):\n",
    "    mel_spectrogram, yin, pyin = data#move_data_to_device(data, 'cpu')\n",
    "    print(mel_spectrogram.shape)\n",
    "    print(yin.shape)\n",
    "    print(pyin.shape)\n",
    "    #assert list(x.shape) == [8, 250, 256]  # shape in [B, T, D],\n",
    "                                # i.e., [Batch size, num of frame per sample, spectrogram feature dimension]\n",
    "    #assert list(onset.shape) == list(offset.shape) == list(octave.shape) == list(pitch_class.shape) == [8, 250]\n",
    "    break\n",
    "print('Congrats!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b11fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the Michigan dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import  get_data_loader_michigan\n",
    "from hparams import Hparams_michigan\n",
    "\n",
    "train_ds, test_ds , data_loader_train, data_loader_test = get_data_loader_michigan(args=Hparams_michigan.args, test_size=0.2)\n",
    "\n",
    "# to plot\n",
    "train_ds.plot_item(0)\n",
    "\n",
    "# data loading\n",
    "for data in tqdm(data_loader_train):\n",
    "    mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, toneclass = data\n",
    "    print(f\"(Batch, feature)\")\n",
    "    print(f\"Spectrogram: {mel_spectrogram_normalised_log_scale_torch.shape} {type(mel_spectrogram_normalised_log_scale_torch)}\")\n",
    "    print(f\"Yin: {yin_normalised_torch.shape} {type(yin_normalised_torch)}\")\n",
    "    print(f\"Pyin: {pyin_normalised_torch.shape} {type(pyin_normalised_torch)}\")\n",
    "    print(f\"Word: {len(word)} {type(word)}\")\n",
    "    print(f\"Toneclass: {toneclass.shape} {type(toneclass)}\")\n",
    "    break\n",
    "print('Congrats!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.buffer = {}\n",
    "\n",
    "    def update(self, out, tgt, loss):\n",
    "        with torch.no_grad():\n",
    "            out = torch.flatten(out)\n",
    "            tgt = torch.flatten(tgt)\n",
    "\n",
    "            # metric computation\n",
    "            f1 = f1_score(tgt.cpu(), out.cpu())\n",
    "            # acc = accuracy_score(tgt.cpu(), out.cpu())\n",
    "\n",
    "            batch_metric = {\n",
    "                'loss': loss.item(),\n",
    "                'f1_score': f1,\n",
    "            }\n",
    "\n",
    "            for k in batch_metric:\n",
    "                if k in self.buffer:\n",
    "                    self.buffer[k].append(batch_metric[k])\n",
    "                else:\n",
    "                    self.buffer[k] = [batch_metric[k]]\n",
    "\n",
    "    def get_value(self):\n",
    "        for k in self.buffer:\n",
    "            self.buffer[k] = sum(self.buffer[k]) / len(self.buffer[k])\n",
    "        ret = self.buffer\n",
    "        self.buffer = {}\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import ToneEval_Base\n",
    "\n",
    "\n",
    "def fit(args, learning_params):\n",
    "    # Set paths\n",
    "    save_model_dir = f\"{args['save_model_dir']}/{learning_params['lr']}\"\n",
    "    if not os.path.exists(save_model_dir):\n",
    "        os.mkdir(save_model_dir)\n",
    "\n",
    "    model = ToneEval_Base(input_shape=(1, 1))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_params['lr'])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    metric = Metrics()\n",
    "\n",
    "    # Start training\n",
    "    print('Start training...')\n",
    "    start_time = time.time()\n",
    "    best_model_id = -1\n",
    "    min_valid_loss = 10000\n",
    "\n",
    "    for epoch in range(1, learning_params['epoch'] + 1):\n",
    "        model.train()\n",
    "        total_training_loss = 0\n",
    "\n",
    "        # Train\n",
    "        pbar = tqdm(data_loader_train)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            x, tone_class = move_data_to_device(batch, args['device'])\n",
    "            out = model(x)\n",
    "            loss = loss_func(out, tone_class)\n",
    "            metric.update(out, tone_class, loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_training_loss += loss.item()\n",
    "\n",
    "            pbar.set_description('Epoch {}, Loss: {:.4f}'.format(epoch, loss.item()))\n",
    "        metric_train = metric.get_value()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(data_loader_test):\n",
    "                x, tone_class = move_data_to_device(batch, args['device'])\n",
    "                out = model(x)\n",
    "                metric.update(out, tone_class)\n",
    "        metric_test = metric.get_value()\n",
    "\n",
    "        # Logging\n",
    "        print('[Epoch {:02d}], Train Loss: {:.5f}, Valid Loss {:.5f}, Time {:.2f}s'.format(\n",
    "            epoch, metric_train['loss'], metric_test['loss'], time.time() - start_time,\n",
    "        ))\n",
    "        print('Split Train Loss, F1: Loss {:.4f} | F1_Score {:.4f}'.format(\n",
    "            metric_train['loss'],\n",
    "            metric_train['f1_score']\n",
    "        ))\n",
    "        print('Split Test Loss, F1: Loss {:.4f} | F1_Score {:.4f}'.format(\n",
    "            metric_test['loss'],\n",
    "            metric_test['f1_score']\n",
    "        ))\n",
    "\n",
    "        # Save the best model\n",
    "        if metric_test['loss'] < min_valid_loss:\n",
    "            min_valid_loss = metric_test['loss']\n",
    "            best_model_id = epoch\n",
    "\n",
    "            save_dict = model.state_dict()\n",
    "            target_model_path = save_model_dir + '/best_model.pth'\n",
    "            torch.save(save_dict, target_model_path)\n",
    "\n",
    "    print('Training done in {:.1f} minutes.'.format((time.time() - start_time) / 60))\n",
    "    return best_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fe830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning params\n",
    "learning_params = {\n",
    "    'batch_size': 50,\n",
    "    'epoch': 10,\n",
    "    'lr': 1e-3,\n",
    "}\n",
    "\n",
    "fit(args=Hparams.args, learning_params=learning_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4347",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
