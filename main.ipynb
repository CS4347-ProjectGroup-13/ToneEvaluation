{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27470f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from hparams import *\n",
    "from dataset import  get_data_loader, get_data_loader_michigan\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b11fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the Michigan dataset\n",
    "train_ds, test_ds, data_loader_train, data_loader_test = get_data_loader_michigan(args=Hparams_michigan.args, test_size=0.4,split_individual=False,test_speakers=Hparams_michigan.args[\"test_speakers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.buffer = {}\n",
    "        self.results_buffer = []\n",
    "\n",
    "    def update(self, out, tgt, loss):\n",
    "        with torch.no_grad():\n",
    "            out = out.argmax(dim=1)\n",
    "            out = torch.flatten(out)\n",
    "            tgt = torch.flatten(tgt)\n",
    "\n",
    "            acc = accuracy_score(tgt.cpu(), out.cpu())\n",
    "            f1 = f1_score(tgt.cpu(), out.cpu(), average='macro')\n",
    "\n",
    "            batch_metric = {\n",
    "                'loss': loss.item(),\n",
    "                'accuracy': acc,\n",
    "                'f1': f1,\n",
    "            }\n",
    "\n",
    "            for k in batch_metric:\n",
    "                if k in self.buffer:\n",
    "                    self.buffer[k].append(batch_metric[k])\n",
    "                else:\n",
    "                    self.buffer[k] = [batch_metric[k]]\n",
    "\n",
    "            self.results_buffer.append((out.cpu(), tgt.cpu()))\n",
    "\n",
    "    def get_value(self):\n",
    "        for k in self.buffer:\n",
    "            self.buffer[k] = sum(self.buffer[k]) / len(self.buffer[k])\n",
    "        ret = self.buffer\n",
    "        ret2 = self.results_buffer\n",
    "        self.buffer = {}\n",
    "        self.results_buffer = []\n",
    "\n",
    "        gt= torch.cat([x[1] for x in ret2]).tolist()\n",
    "        pred= torch.cat([x[0] for x in ret2]).tolist()\n",
    "        report= classification_report(gt, pred, output_dict=False, digits=4)\n",
    "\n",
    "        return ret, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data_loader, move_data_to_device\n",
    "\n",
    "import json\n",
    "\n",
    "TRAINLOSSES = []\n",
    "TESTLOSSES = []\n",
    "\n",
    "def fit(model, args,learning_params, save_model_dir_override=None):\n",
    "    # Set paths\n",
    "    dev = args['device']\n",
    "    print(f\"Starting Training on {dev}\")\n",
    "    featureset = data_loader_train.dataset.features\n",
    "    print(f\"Featureset: {featureset}\")        \n",
    "    save_model_dir = f\"{args['save_model_dir']}{model.feat_dim}_lr-{learning_params['lr']}\"\n",
    "    if save_model_dir_override is not None:\n",
    "        save_model_dir = f\"{args['save_model_dir']}{save_model_dir_override}\"\n",
    "\n",
    "    if not os.path.exists(save_model_dir):\n",
    "        os.mkdir(save_model_dir)\n",
    "\n",
    "    with open(save_model_dir + '/trainingParams.json', 'w') as f:\n",
    "        print(json.dumps(Hparams_michigan.args), file=f)\n",
    "\n",
    "    model.to(args['device'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_params['lr'])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    metric = Metrics()\n",
    "    \n",
    "    # Start training\n",
    "    print('Start training...')\n",
    "    start_time = time.time()\n",
    "    best_model_id = -1\n",
    "    min_valid_loss = 10000\n",
    "    prev_loss = 10000\n",
    "    threshold = 1e-6\n",
    "\n",
    "    for epoch in range(1, learning_params['epoch'] + 1):\n",
    "        model.train()\n",
    "        \n",
    "        # Train\n",
    "        pbar = tqdm(data_loader_train)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "            tone_class -= 1 # 0-index\n",
    "        \n",
    "            x = mel_spectrogram_normalised_log_scale_torch.to(args['device'])\n",
    "            x = x[:, None, :, :]\n",
    "            tgt = tone_class.to(args['device'])\n",
    "            out = model(x)\n",
    "            loss = loss_func(out, tgt)\n",
    "            metric.update(out, tgt, loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description('Epoch {}, Loss: {:.4f}'.format(epoch, loss.item()))\n",
    "        metric_train,_ = metric.get_value()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(data_loader_test):\n",
    "                mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "                tone_class -= 1 # 0-index\n",
    "\n",
    "                x = mel_spectrogram_normalised_log_scale_torch.to(args['device'])\n",
    "                x = x[:, None, :, :]\n",
    "                tgt = tone_class.to(args['device'])\n",
    "                out = model(x)\n",
    "                loss = loss_func(out, tgt)\n",
    "                metric.update(out, tgt, loss)\n",
    "        metric_test,report = metric.get_value()\n",
    "\n",
    "        # Logging\n",
    "        print('[Epoch {:02d}], Train Loss: {:.5f}, Valid Loss {:.5f}, Time {:.2f}s'.format(\n",
    "            epoch, metric_train['loss'], metric_test['loss'], time.time() - start_time,\n",
    "        ))\n",
    "        print('Split Train Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_train['loss'],\n",
    "            metric_train['accuracy']\n",
    "        ))\n",
    "        print('Split Test Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_test['loss'],\n",
    "            metric_test['accuracy']\n",
    "        ))\n",
    "\n",
    "        TRAINLOSSES.append((metric_train['loss'],metric_train['accuracy'],metric_train['f1']))\n",
    "        TESTLOSSES.append((metric_test['loss'],metric_test['accuracy'],metric_test['f1']))\n",
    "\n",
    "        print('Classification Report:')\n",
    "        print(report)\n",
    "\n",
    "        \n",
    "        # Save the best model\n",
    "        saved = False\n",
    "        if metric_test['loss'] < min_valid_loss:\n",
    "            min_valid_loss = metric_test['loss']\n",
    "            best_model_id = epoch\n",
    "\n",
    "            save_dict = model.state_dict()\n",
    "            target_model_path = save_model_dir + '/best_model.pth'\n",
    "            torch.save(save_dict, target_model_path)\n",
    "            saved = True\n",
    "        \n",
    "        with open(save_model_dir + '/training_log.txt', 'a') as f:\n",
    "            print(f\"====EPOCH {epoch} ====  saved:{saved}\", file=f)\n",
    "            print('[Epoch {:02d}], Train Loss: {:.5f}, Valid Loss {:.5f}, Time {:.2f}s'.format(\n",
    "                epoch, metric_train['loss'], metric_test['loss'], time.time() - start_time,\n",
    "            ),file=f)\n",
    "            print('Split Train Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "                metric_train['loss'],\n",
    "                metric_train['accuracy']\n",
    "            ),file=f)\n",
    "            print('Split Test Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "                metric_test['loss'],\n",
    "                metric_test['accuracy']\n",
    "            ),file=f)\n",
    "            print(report, file=f)\n",
    "\n",
    "        if abs(metric_test['loss'] - prev_loss) < threshold:\n",
    "            break\n",
    "\n",
    "        prev_loss = metric_test['loss']\n",
    "\n",
    "\n",
    "\n",
    "    print('Training done in {:.1f} minutes.'.format((time.time() - start_time) / 60))\n",
    "    return best_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fe830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning params\n",
    "learning_params = {\n",
    "    'epoch': 10,\n",
    "    'lr': 1e-3,\n",
    "}\n",
    "\n",
    "model = ToneEval_Base(input_shape=(1, 128, 75))\n",
    "fit(model, args=Hparams.args, learning_params=learning_params, save_model_dir_override='config1_testMV1')\n",
    "# model.load_state_dict(torch.load('results/1024_lr-0.001/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c341a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function plots matplotlib for accuracy and loss\n",
    "print(TRAINLOSSES)\n",
    "print(TESTLOSSES)\n",
    "\n",
    "def validateModel(model, device):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    metric = Metrics()\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader_test):\n",
    "            mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "            tone_class -= 1 # 0-index\n",
    "\n",
    "            x = mel_spectrogram_normalised_log_scale_torch.to(device)\n",
    "            print(x.shape)\n",
    "\n",
    "            x = x[:, None, :, :]\n",
    "            print(x.shape)\n",
    "\n",
    "            tgt = tone_class.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_func(out, tgt)\n",
    "            metric.update(out, tgt, loss)\n",
    "    metric_test,report = metric.get_value()\n",
    "\n",
    "    print('[Epoch {:02d}], Train Loss: {:.5f}, Valid Loss {:.5f}, Time {:.2f}s'.format(\n",
    "            epoch, metric_train['loss'], metric_test['loss'], time.time() - time.time(),\n",
    "        ))\n",
    "    print('Split Train Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_train['loss'],\n",
    "            metric_train['accuracy']\n",
    "        ))\n",
    "    print('Split Test Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_test['loss'],\n",
    "            metric_test['accuracy']\n",
    "        ))\n",
    "    return metric_test,report\n",
    "validateModel(model, \"cuda\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
