{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27470f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from hparams import *\n",
    "from dataset import  get_data_loader, get_data_loader_michigan\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa9f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 5])\n",
      "torch.Size([8, 256])\n",
      "torch.Size([8, 256])\n",
      "Congrats!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#new jupyter notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = get_data_loader(split='train', args=Hparams.args)\n",
    "for data in tqdm(train_loader):\n",
    "    mel_spectrogram, yin, pyin = data#move_data_to_device(data, 'cpu')\n",
    "    print(mel_spectrogram.shape)\n",
    "    print(yin.shape)\n",
    "    print(pyin.shape)\n",
    "    #assert list(x.shape) == [8, 250, 256]  # shape in [B, T, D],\n",
    "                                # i.e., [Batch size, num of frame per sample, spectrogram feature dimension]\n",
    "    #assert list(onset.shape) == list(offset.shape) == list(octave.shape) == list(pitch_class.shape) == [8, 250]\n",
    "    break\n",
    "print('Congrats!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b11fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the Michigan dataset\n",
    "train_ds, test_ds, data_loader_train, data_loader_test = get_data_loader_michigan(args=Hparams_michigan.args, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d28c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/246 [01:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Batch, feature)\n",
      "Spectrogram: torch.Size([32, 128, 75]) <class 'torch.Tensor'>\n",
      "Yin: torch.Size([32, 481]) <class 'torch.Tensor'>\n",
      "Pyin: torch.Size([32, 501]) <class 'torch.Tensor'>\n",
      "Word: 32 <class 'tuple'>\n",
      "Toneclass: torch.Size([32]) <class 'torch.Tensor'> tensor([1, 1, 4, 2, 4, 1, 2, 3, 1, 2, 2, 4, 3, 2, 3, 4, 3, 1, 4, 1, 2, 1, 4, 2,\n",
      "        3, 1, 4, 1, 1, 4, 3, 1])\n",
      "Congrats!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# to plot\n",
    "# train_ds.plot_item(0)\n",
    "\n",
    "# data loading\n",
    "for data in tqdm(data_loader_train):\n",
    "    mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, toneclass = data\n",
    "    print(f\"(Batch, feature)\")\n",
    "    print(f\"Spectrogram: {mel_spectrogram_normalised_log_scale_torch.shape} {type(mel_spectrogram_normalised_log_scale_torch)}\")\n",
    "    print(f\"Yin: {yin_normalised_torch.shape} {type(yin_normalised_torch)}\")\n",
    "    print(f\"Pyin: {pyin_normalised_torch.shape} {type(pyin_normalised_torch)}\")\n",
    "    print(f\"Word: {len(word)} {type(word)}\")\n",
    "    print(f\"Toneclass: {toneclass.shape} {type(toneclass)} {toneclass}\")\n",
    "    break\n",
    "print('Congrats!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc5059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.buffer = {}\n",
    "\n",
    "    def update(self, out, tgt, loss):\n",
    "        with torch.no_grad():\n",
    "            out = out.argmax(dim=1)\n",
    "            out = torch.flatten(out)\n",
    "            tgt = torch.flatten(tgt)\n",
    "\n",
    "            acc = accuracy_score(tgt.cpu(), out.cpu())\n",
    "\n",
    "            batch_metric = {\n",
    "                'loss': loss.item(),\n",
    "                'accuracy': acc,\n",
    "            }\n",
    "\n",
    "            for k in batch_metric:\n",
    "                if k in self.buffer:\n",
    "                    self.buffer[k].append(batch_metric[k])\n",
    "                else:\n",
    "                    self.buffer[k] = [batch_metric[k]]\n",
    "\n",
    "    def get_value(self):\n",
    "        for k in self.buffer:\n",
    "            self.buffer[k] = sum(self.buffer[k]) / len(self.buffer[k])\n",
    "        ret = self.buffer\n",
    "        self.buffer = {}\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0992609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data_loader, move_data_to_device\n",
    "\n",
    "\n",
    "def fit(model, args, learning_params):\n",
    "    # Set paths\n",
    "    save_model_dir = f\"{args['save_model_dir']}{model.feat_dim}_lr-{learning_params['lr']}\"\n",
    "    if not os.path.exists(save_model_dir):\n",
    "        os.mkdir(save_model_dir)\n",
    "\n",
    "    model.to(args['device'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_params['lr'])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    metric = Metrics()\n",
    "\n",
    "    # Start training\n",
    "    print('Start training...')\n",
    "    start_time = time.time()\n",
    "    best_model_id = -1\n",
    "    min_valid_loss = 10000\n",
    "    prev_loss = 10000\n",
    "    threshold = 1e-6\n",
    "\n",
    "    for epoch in range(1, learning_params['epoch'] + 1):\n",
    "        model.train()\n",
    "        \n",
    "        # Train\n",
    "        pbar = tqdm(data_loader_train)\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "            tone_class -= 1 # 0-index\n",
    "        \n",
    "            x = mel_spectrogram_normalised_log_scale_torch.to(args['device'])\n",
    "            x = x[:, None, :, :]\n",
    "            tgt = tone_class.to(args['device'])\n",
    "            out = model(x)\n",
    "            loss = loss_func(out, tgt)\n",
    "            metric.update(out, tgt, loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_description('Epoch {}, Loss: {:.4f}'.format(epoch, loss.item()))\n",
    "        metric_train = metric.get_value()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(data_loader_test):\n",
    "                mel_spectrogram_normalised_log_scale_torch, yin_normalised_torch, pyin_normalised_torch, word, tone_class = batch\n",
    "                tone_class -= 1 # 0-index\n",
    "\n",
    "                x = mel_spectrogram_normalised_log_scale_torch.to(args['device'])\n",
    "                x = x[:, None, :, :]\n",
    "                tgt = tone_class.to(args['device'])\n",
    "                out = model(x)\n",
    "                loss = loss_func(out, tgt)\n",
    "                metric.update(out, tgt, loss)\n",
    "        metric_test = metric.get_value()\n",
    "\n",
    "        # Logging\n",
    "        print('[Epoch {:02d}], Train Loss: {:.5f}, Valid Loss {:.5f}, Time {:.2f}s'.format(\n",
    "            epoch, metric_train['loss'], metric_test['loss'], time.time() - start_time,\n",
    "        ))\n",
    "        print('Split Train Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_train['loss'],\n",
    "            metric_train['accuracy']\n",
    "        ))\n",
    "        print('Split Test Loss, Accuracy: Loss {:.4f} | Accuracy {:.4f}'.format(\n",
    "            metric_test['loss'],\n",
    "            metric_test['accuracy']\n",
    "        ))\n",
    "\n",
    "        # Save the best model\n",
    "        if metric_test['loss'] < min_valid_loss:\n",
    "            min_valid_loss = metric_test['loss']\n",
    "            best_model_id = epoch\n",
    "\n",
    "            save_dict = model.state_dict()\n",
    "            target_model_path = save_model_dir + '/best_model.pth'\n",
    "            torch.save(save_dict, target_model_path)\n",
    "\n",
    "        if abs(metric_test['loss'] - prev_loss) < threshold:\n",
    "            break\n",
    "\n",
    "        prev_loss = metric_test['loss']\n",
    "\n",
    "    print('Training done in {:.1f} minutes.'.format((time.time() - start_time) / 60))\n",
    "    return best_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "947fe830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7451: 100%|██████████| 246/246 [1:27:53<00:00, 21.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01], Train Loss: 0.78702, Valid Loss 0.75133, Time 6639.65s\n",
      "Split Train Loss, Accuracy: Loss 0.7870 | Accuracy 0.9564\n",
      "Split Test Loss, Accuracy: Loss 0.7513 | Accuracy 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7464: 100%|██████████| 246/246 [1:25:02<00:00, 20.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 02], Train Loss: 0.75874, Valid Loss 0.77568, Time 13062.78s\n",
      "Split Train Loss, Accuracy: Loss 0.7587 | Accuracy 0.9848\n",
      "Split Test Loss, Accuracy: Loss 0.7757 | Accuracy 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.7442: 100%|██████████| 246/246 [1:26:08<00:00, 21.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 03], Train Loss: 0.75964, Valid Loss 0.74767, Time 19565.92s\n",
      "Split Train Loss, Accuracy: Loss 0.7596 | Accuracy 0.9841\n",
      "Split Test Loss, Accuracy: Loss 0.7477 | Accuracy 0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.7515: 100%|██████████| 246/246 [1:25:55<00:00, 20.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 04], Train Loss: 0.74946, Valid Loss 0.75915, Time 26072.20s\n",
      "Split Train Loss, Accuracy: Loss 0.7495 | Accuracy 0.9944\n",
      "Split Test Loss, Accuracy: Loss 0.7592 | Accuracy 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.7437: 100%|██████████| 246/246 [1:27:35<00:00, 21.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 05], Train Loss: 0.75443, Valid Loss 0.74918, Time 32672.48s\n",
      "Split Train Loss, Accuracy: Loss 0.7544 | Accuracy 0.9895\n",
      "Split Test Loss, Accuracy: Loss 0.7492 | Accuracy 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.8037: 100%|██████████| 246/246 [1:26:37<00:00, 21.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 06], Train Loss: 0.75328, Valid Loss 0.75276, Time 39219.67s\n",
      "Split Train Loss, Accuracy: Loss 0.7533 | Accuracy 0.9905\n",
      "Split Test Loss, Accuracy: Loss 0.7528 | Accuracy 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.7446: 100%|██████████| 246/246 [1:25:52<00:00, 20.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 07], Train Loss: 0.75212, Valid Loss 0.75630, Time 45734.89s\n",
      "Split Train Loss, Accuracy: Loss 0.7521 | Accuracy 0.9912\n",
      "Split Test Loss, Accuracy: Loss 0.7563 | Accuracy 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.8369: 100%|██████████| 246/246 [1:27:50<00:00, 21.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 08], Train Loss: 0.75342, Valid Loss 0.74403, Time 52365.54s\n",
      "Split Train Loss, Accuracy: Loss 0.7534 | Accuracy 0.9901\n",
      "Split Test Loss, Accuracy: Loss 0.7440 | Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.7438: 100%|██████████| 246/246 [1:28:16<00:00, 21.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 09], Train Loss: 0.75207, Valid Loss 0.75403, Time 59019.99s\n",
      "Split Train Loss, Accuracy: Loss 0.7521 | Accuracy 0.9917\n",
      "Split Test Loss, Accuracy: Loss 0.7540 | Accuracy 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.7437: 100%|██████████| 246/246 [1:29:48<00:00, 21.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10], Train Loss: 0.75009, Valid Loss 0.74684, Time 65815.95s\n",
      "Split Train Loss, Accuracy: Loss 0.7501 | Accuracy 0.9934\n",
      "Split Test Loss, Accuracy: Loss 0.7468 | Accuracy 0.9970\n",
      "Training done in 1096.9 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set learning params\n",
    "learning_params = {\n",
    "    'epoch': 10,\n",
    "    'lr': 1e-3,\n",
    "}\n",
    "\n",
    "model = ToneEval_Base(input_shape=(1, 128, 75))\n",
    "fit(model, args=Hparams.args, learning_params=learning_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4347",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
