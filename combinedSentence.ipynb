{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "from dataset import FusedSentenceMichigan\n",
    "\n",
    "\n",
    "\n",
    "DATASET =FusedSentenceMichigan(feature_options={},dataset_size=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import run_segmentation\n",
    "\n",
    "SEGMENTATION_RESULTS, DATASET_PROPERTIES = run_segmentation(dataset=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PROPERTIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataset\n",
    "importlib.reload(dataset)\n",
    "from dataset import processes_segementation_results_global\n",
    "PROCESSED_SEGEMENTATION_DATASET, PROCESSED_SEGMENTAION_AUDIO_DATASET = processes_segementation_results_global(SEGMENTATION_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_SEGEMENTATION_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def convert_segmentations_to_index(segmentations, convert_fn = lambda x: x.replace(\"5\", \"4\")):\n",
    "    finalResults = []\n",
    "    for i in range(len(segmentations)):\n",
    "        results_entry = segmentations.iloc[i]\n",
    "        word_count = results_entry['word_count']\n",
    "        sentence = results_entry['sentence_results']\n",
    "        mappings = results_entry['mappings']\n",
    "        split_sentence = sentence.split(\"_\")\n",
    "        split_sentence = [convert_fn(x) for x in split_sentence]\n",
    "        for j in range(len(split_sentence)):\n",
    "            word_id = split_sentence[j] \n",
    "            toneclass = int(word_id[-1])\n",
    "            main_Idx = i\n",
    "            word_Idx = j\n",
    "            mapped_onset = mappings[j]\n",
    "            finalResults.append((word_id, toneclass, main_Idx, word_Idx,mapped_onset))\n",
    "\n",
    "        \n",
    "    return pd.DataFrame(finalResults, columns=['word_id', 'toneclass', 'main_Idx', 'word_Idx', 'mapped_onset'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PSEG_INDEX = convert_segmentations_to_index(PROCESSED_SEGEMENTATION_DATASET)\n",
    "PSEG_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def get_audio_sample_at_idx(idx,pSEG_index, pSEG, pSEGAUDIO, sr= 16000):\n",
    "    sample_info = pSEG_index.iloc[idx]\n",
    "    pSEG_idx = sample_info['main_Idx']\n",
    "\n",
    "    sentence_info = pSEG.iloc[pSEG_idx]\n",
    "    pSEG_audio = pSEGAUDIO.iloc[pSEG_idx]\n",
    "\n",
    "\n",
    "    segementation_start_time_gt = sentence_info['delimiter_time_results']\n",
    "    segementation_start_time = sentence_info['segementation_times_results'] + [segementation_start_time_gt[-1]]\n",
    "    segmentation_onset_mapping = sentence_info['mappings']\n",
    "    mapped_onset = sample_info['mapped_onset']\n",
    "\n",
    "    current_mapping = segmentation_onset_mapping[sample_info['word_Idx']]\n",
    "\n",
    "    if current_mapping == -1:\n",
    "        # unmapped, use previous result\n",
    "        prev_mapping = segmentation_onset_mapping[sample_info['word_Idx'] - 1]\n",
    "        start_time = segementation_start_time[prev_mapping]\n",
    "        end_time = segementation_start_time[prev_mapping+1]    \n",
    "    else:\n",
    "        start_time = segementation_start_time[current_mapping]\n",
    "        end_time = segementation_start_time[current_mapping+1]\n",
    "\n",
    "    start_samples = librosa.time_to_samples(start_time, sr=sr)\n",
    "    end_samples = librosa.time_to_samples(end_time, sr=sr)\n",
    "\n",
    "    return pSEG_audio[start_samples:end_samples]\n",
    "\n",
    "for i in range(len(PSEG_INDEX)):\n",
    "    print(get_audio_sample_at_idx(i, PSEG_INDEX, PROCESSED_SEGEMENTATION_DATASET, PROCESSED_SEGMENTAION_AUDIO_DATASET))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
