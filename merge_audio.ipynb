{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import os\n",
    "import re\n",
    "\n",
    "DATA_ROOT_DIR = './data_full/michigan/tone_perfect_all_mp3/tone_perfect/'\n",
    "EXPORT_DIR = './data_synthesized/'\n",
    "\n",
    "def remove_extension(file_path):\n",
    "    root, extension = os.path.splitext(file_path)\n",
    "    return root\n",
    "\n",
    "def merge_audio_and_label(root_dir, export_dir, path1, path2):\n",
    "    \"\"\"returns label and path to merged audio\n",
    "    label of type dictionary\n",
    "    key: path to merged audio\n",
    "    value: list of tuples. tuple(tone, start time in seconds, end time in seconds)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(export_dir):\n",
    "        os.makedirs(export_dir)\n",
    "\n",
    "    label = {}\n",
    "\n",
    "    audio1 = AudioSegment.from_mp3(root_dir + path1)\n",
    "    audio2 = AudioSegment.from_mp3(root_dir + path2)\n",
    "    merged_audio = audio1 + audio2\n",
    "    new_path = remove_extension(path1) + '_' + remove_extension(path2) + '.mp3'\n",
    "    merged_audio.export(export_dir + new_path, format='mp3')\n",
    "\n",
    "    tone1 = str(re.search(r'\\d', path1).group())\n",
    "    tone2 = str(re.search(r'\\d', path2).group())\n",
    "    label[new_path] =[]\n",
    "    label[new_path].append((tone1, 0, audio1.duration_seconds))\n",
    "    label[new_path].append((tone2, audio1.duration_seconds, audio1.duration_seconds + audio2.duration_seconds))\n",
    "\n",
    "    return label\n",
    "\n",
    "#    duration1 = librosa.get_duration(filename=path1)\n",
    "#    duration2 = librosa.get_duration(filename=path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a1_FV1_MP3_a4_FV2_MP3.mp3': [('1', 0, 0.6802494331065759),\n",
       "  ('4', 0.6802494331065759, 1.177641723356009)]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = \"a1_FV1_MP3.mp3\"\n",
    "path2 = \"a4_FV2_MP3.mp3\"\n",
    "\n",
    "merge_audio_and_label(DATA_ROOT_DIR, EXPORT_DIR, path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "def prepare_audio_files(root_dir):\n",
    "    audio_files = []\n",
    "    for file_path in os.listdir(root_dir):\n",
    "        tone = str(re.search(r'\\d', file_path).group())\n",
    "        audio = AudioSegment.from_mp3(root_dir + file_path)\n",
    "        audio_files.append((remove_extension(file_path), audio, tone, audio.duration_seconds))\n",
    "    return audio_files\n",
    "\n",
    "def sythesize_data(export_dir, audio_files, duration=10, min_num_clips=5, max_num_clips=10, num_total=100, train_split=0.8, seed=None):\n",
    "    INTERVAL_FACTOR = 10\n",
    "\n",
    "    random.seed(a=seed)\n",
    "    num_total_train = math.ceil(num_total * train_split)\n",
    "    num_total_test = num_total - num_total_train\n",
    "\n",
    "    assert num_total_train < num_total\n",
    "    assert num_total_test > 0\n",
    "\n",
    "    train_dir = export_dir + 'train/'\n",
    "    test_dir = export_dir + 'test/'\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    train_labels = {}\n",
    "    test_labels = {}\n",
    "    train_merged_filenames = {}\n",
    "    test_merged_filenames = {}\n",
    "\n",
    "    def merge_audio(i, mode):\n",
    "        num_to_sample = 0\n",
    "        audio_clips = []\n",
    "        while True:\n",
    "            num_to_sample = random.randint(min_num_clips, max_num_clips)\n",
    "            audio_clips = random.sample(population=audio_files, k=num_to_sample)\n",
    "            \n",
    "            total_duration = 0\n",
    "            for clip in audio_clips:\n",
    "                total_duration += clip[3]\n",
    "            if total_duration < duration:\n",
    "                break\n",
    "        \n",
    "        total_padding_duration = duration - total_duration\n",
    "        start_idx = 0\n",
    "        onset_time = 0\n",
    "\n",
    "        if mode == 'train':\n",
    "            file_name = f'train_{i + 1}.mp3'\n",
    "            train_labels[file_name] = []\n",
    "            train_merged_filenames[file_name] = []\n",
    "        elif mode == 'test':\n",
    "            file_name = f'test_{i + 1}.mp3'\n",
    "            test_labels[file_name] = []\n",
    "            test_merged_filenames[file_name] = []\n",
    "\n",
    "        merged_audio = AudioSegment.empty()\n",
    "        for j in range(num_to_sample - 1):\n",
    "            if mode == 'train':\n",
    "                train_labels[file_name].append((audio_clips[j][2], onset_time, (onset_time + audio_clips[j][3])))\n",
    "                train_merged_filenames[file_name].append(audio_clips[j][0])\n",
    "            elif mode == 'test':\n",
    "                test_labels[file_name].append((audio_clips[j][2], onset_time, (onset_time + audio_clips[j][3])))\n",
    "                test_merged_filenames[file_name].append(audio_clips[j][0])      \n",
    "\n",
    "            audio = audio_clips[j][1]\n",
    "            merged_audio += audio\n",
    "\n",
    "            random_idx = random.randint(start_idx, (j + 1) * INTERVAL_FACTOR)\n",
    "            padding_duration = ((random_idx - start_idx) / ((num_to_sample - 1) * INTERVAL_FACTOR)) * total_padding_duration\n",
    "            padding = AudioSegment.silent(duration=padding_duration)\n",
    "            merged_audio += padding\n",
    "\n",
    "            start_idx = random_idx\n",
    "            onset_time += (audio_clips[j][3] + padding_duration)\n",
    "\n",
    "        merged_audio += audio_clips[-1][1]       \n",
    "        if mode == 'train':\n",
    "            train_labels[file_name].append((audio_clips[-1][2], onset_time, (onset_time + audio_clips[-1][3])))\n",
    "            train_merged_filenames[file_name].append(audio_clips[-1][0])\n",
    "            merged_audio.export(train_dir + file_name, format='mp3')\n",
    "        elif mode == 'test':\n",
    "            test_labels[file_name].append((audio_clips[-1][2], onset_time, (onset_time + audio_clips[-1][3])))\n",
    "            test_merged_filenames[file_name].append(audio_clips[-1][0])\n",
    "            merged_audio.export(test_dir + file_name, format='mp3')\n",
    "\n",
    "    \n",
    "    for i in range(num_total_train):\n",
    "        merge_audio(i, 'train')\n",
    "    \n",
    "    with open(train_dir + 'train_labels.json', 'w', encoding='utf8') as f:\n",
    "        f.write(json.dumps(train_labels, indent=4, sort_keys=False, ensure_ascii=False))\n",
    "    with open(train_dir + 'train_merged_filenames.json', 'w', encoding='utf8') as f:\n",
    "        f.write(json.dumps(train_merged_filenames, indent=4, sort_keys=False, ensure_ascii=False))\n",
    "    print(f'Done synthesizing {num_total_train} audio files in {train_dir}')\n",
    "\n",
    "    for i in range(num_total_test):\n",
    "        merge_audio(i, 'test')\n",
    "    with open(test_dir + 'test_labels.json', 'w', encoding='utf8') as f:\n",
    "        f.write(json.dumps(test_labels, indent=4, sort_keys=False, ensure_ascii=False))\n",
    "    with open(test_dir + 'test_merged_filenames.json', 'w', encoding='utf8') as f:\n",
    "        f.write(json.dumps(test_merged_filenames, indent=4, sort_keys=False, ensure_ascii=False))\n",
    "    print(f'Done synthesizing {num_total_test} audio files in {test_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = prepare_audio_files(DATA_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done synthesizing 8 audio files in ./data_synthesized/train/\n",
      "Done synthesizing 2 audio files in ./data_synthesized/test/\n"
     ]
    }
   ],
   "source": [
    "sythesize_data(EXPORT_DIR, audio_files, num_total=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4347",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
